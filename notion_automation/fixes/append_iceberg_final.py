import requests
import time
import json


import os

def _get_notion_token():
    # Try multiple paths to find notion_key.txt
    current_dir = os.path.dirname(os.path.abspath(__file__))
    paths = [
        os.path.join(current_dir, 'notion_key.txt'),
        os.path.join(current_dir, '..', 'core', 'notion_key.txt'),
        os.path.join(current_dir, 'core', 'notion_key.txt'),
        os.path.join(os.getcwd(), 'notion_automation', 'core', 'notion_key.txt')
    ]
    for p in paths:
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                if token: return token
    return os.getenv("NOTION_TOKEN", "YOUR_NOTION_TOKEN_HERE")

NOTION_TOKEN = _get_notion_token()
PAGE_ID = '2f0eacc8-175a-805c-85b2-dca59899d3d8'
HEADERS = {
    'Authorization': f'Bearer {NOTION_TOKEN}',
    'Content-Type': 'application/json',
    'Notion-Version': '2022-06-28'
}

def update_notion_final():
    # 1. ì›ë³¸ íŒŒì¼ì—ì„œ ìƒˆë¡œ ì‘ì„±ëœ 'í¼í™íŠ¸' ì½”ë“œ ì½ê¸°
    with open('gitp/BFS/2573ëíŒì™• bfs ë™ì‹œíƒìƒ‰ì‹œ ì‹œê°„ì´ˆê³¼ ë”°ë¼ì„œ ë³€ë™ê°’ ë¦¬ìŠ¤íŠ¸ ì €ì¥.py', 'r', encoding='utf-8') as f:
        verbatim_code = f.read()

    # 2. ë…¸ì…˜ìš© ë¸”ë¡ êµ¬ì„±
    blocks = [
        {'type': 'divider', 'divider': {}},
        {'type': 'heading_1', 'heading_1': {'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ“ [Samsung A] ë¹™ì‚° - BFS ê¸°ë°˜ ë™ì‹œ ì‹œë®¬ë ˆì´ì…˜ (ìµœì¢… ì™„ì„±ë³¸)'}}]}},
        {'type': 'quote', 'quote': {'rich_text': [{'type': 'text', 'text': {'content': 'IM ì´ˆì›” ìµœì í™” ì „ëµ(ëª…ë‹¨ ê´€ë¦¬, ì˜ˆì•½ ì‹œìŠ¤í…œ, ë‹¤ì´ì–´íŠ¸ ê¸°ë²•)ì´ 100% ë°˜ì˜ëœ ìµœì¢… ì •ë‹µ ì½”ë“œì™€ ìƒì„¸ í•´ì„¤ì…ë‹ˆë‹¤.'}}]}},
        {'type': 'heading_2', 'heading_2': {'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ’» Python ì „ì²´ ì •ë‹µ ì½”ë“œ (ê³ ë°€ë„ ìƒì„¸ ì£¼ì„)'}}]}},
        {'type': 'code', 'code': {'language': 'python', 'rich_text': [{'type': 'text', 'text': {'content': verbatim_code.strip()}}]}},
        {'type': 'callout', 'callout': {'icon': {'type': 'emoji', 'emoji': 'ğŸ’¡'}, 'rich_text': [{'type': 'text', 'text': {'content': 'í•™ìƒ ê°€ì´ë“œ: 9ë§Œ ì¹¸ ì „ìˆ˜ ì¡°ì‚¬ ëŒ€ì‹  ice_list(ëª…ë‹¨)ë¥¼ í™œìš©í•˜ëŠ” ìŠµê´€ì´ Aí˜• í•©ê²©ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ìŠ¤ëƒ…ìƒ· ê¸°ë²•ì„ í†µí•´ ë™ì‹œì„± ì²˜ë¦¬ë¥¼ ì™„ë²½íˆ êµ¬í˜„í•˜ì„¸ìš”.'}}]}}
    ]

    # 3. ê¸°ì¡´ ë¸”ë¡ ì‚­ì œ (ì¤‘ë³µ ë°©ì§€ ë° êµì²´)
    url = f'https://api.notion.com/v1/blocks/{PAGE_ID}/children'
    res = requests.get(url, headers=HEADERS)
    all_blocks = res.json().get('results', [])
    
    target_start_index = -1
    for i, b in enumerate(all_blocks):
        if b['type'] == 'heading_1' and 'ë¹™ì‚°' in b['heading_1']['rich_text'][0]['plain_text']:
            target_start_index = i
            break
            
    if target_start_index != -1:
        print(f"Cleaning up old blocks from index {target_start_index}...")
        for b in all_blocks[target_start_index:]:
            requests.delete(f'https://api.notion.com/v1/blocks/{b["id"]}', headers=HEADERS)
            time.sleep(0.1)

    # 4. ìƒˆë¡œìš´ ì½˜í…ì¸  ì¶”ê°€
    for i in range(0, len(blocks), 5):
        chunk = blocks[i:i+5]
        requests.patch(url, headers=HEADERS, json={'children': chunk})
        time.sleep(1)
    print("Success: Notion updated with the rewritten perfect Iceberg code.")

if __name__ == '__main__':
    update_notion_final()
