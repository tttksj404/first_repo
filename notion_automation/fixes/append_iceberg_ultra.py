import requests
import time
import json


import os

def _get_notion_token():
    # Try multiple paths to find notion_key.txt
    current_dir = os.path.dirname(os.path.abspath(__file__))
    paths = [
        os.path.join(current_dir, 'notion_key.txt'),
        os.path.join(current_dir, '..', 'core', 'notion_key.txt'),
        os.path.join(current_dir, 'core', 'notion_key.txt'),
        os.path.join(os.getcwd(), 'notion_automation', 'core', 'notion_key.txt')
    ]
    for p in paths:
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                if token: return token
    return os.getenv("NOTION_TOKEN", "YOUR_NOTION_TOKEN_HERE")

NOTION_TOKEN = _get_notion_token()
PAGE_ID = '2f0eacc8-175a-805c-85b2-dca59899d3d8'
HEADERS = {
    'Authorization': f'Bearer {NOTION_TOKEN}',
    'Content-Type': 'application/json',
    'Notion-Version': '2022-06-28'
}

# 1. ì›ë³¸ íŒŒì¼ì˜ ë‚´ìš©ì„ 100% ë³´ì¡´í•˜ë©°, ì¶”ê°€ì ì¸ 'ê°•ì˜ì‹ ìƒì„¸ ì£¼ì„'ì„ ì½”ë“œ ë¼ì¸ë³„ë¡œ ë³´ì¶©í•œ ë²„ì „
super_detailed_code = """'''
[ë¹™ì‚° ë¬¸ì œ - BFS & ì‹œë®¬ë ˆì´ì…˜ ìƒì„¸ ì „ëµ]
1. BFSë¡œ ë©ì–´ë¦¬ ê°œìˆ˜ íŒŒì•…: ë¹™ì‚°ì´ 1ì´ìƒì¸ ê³³ì—ì„œ ì‹œì‘í•˜ì—¬ ì‚¬ë°© íƒìƒ‰.
2. ë…¹ì´ê¸° ë¡œì§: ë¹™ì‚°ì˜ ë™ì„œë‚¨ë¶ ì¤‘ '0'(ë°”ë‹¤)ì˜ ê°œìˆ˜ë§Œí¼ ë†’ì´ê°€ ì¤„ì–´ë“¦.
3. ì£¼ì˜ì‚¬í•­: ë…¹ëŠ” ê³¼ì •ì€ 'ë™ì‹œ'ì— ì§„í–‰ë˜ì–´ì•¼ í•¨ (ì˜ˆì•½ ì‹œìŠ¤í…œ í•„ìˆ˜).
4. ì‹œê°„ ë³µì¡ë„ ìµœì í™”: 9ë§Œ ì¹¸(300x300)ì„ ë§¤ë²ˆ ë„ëŠ” ëŒ€ì‹ , ë¹™ì‚° ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸(ice_list)ë§Œ ê´€ë¦¬.
'''

from collections import deque
import sys
input = sys.stdin.readline

# N: í–‰ì˜ ê°œìˆ˜, M: ì—´ì˜ ê°œìˆ˜
N, M = map(int, input().split())
ice = []
ice_list = [] # <--- ì´ê²Œ ë°”ë¡œ ê·¸ 'ìª½ì§€'ì…ë‹ˆë‹¤! (ë¹™ì‚°ì´ ìˆëŠ” ìœ„ì¹˜ë§Œ ëª…ë‹¨ìœ¼ë¡œ ê´€ë¦¬)

for i in range(N):
    row = list(map(int, input().split()))
    ice.append(row)
    for j in range(M):
        if row[j] > 0:
            ice_list.append((i, j)) # ì²˜ìŒ ë¹™ì‚° ìœ„ì¹˜ë§Œ ë”± ì €ì¥í•´ë‘¬ìš”. (ì´ˆê¸° ëª…ë‹¨ í™•ë³´)

# ìƒí•˜ì¢Œìš° íƒìƒ‰ì„ ìœ„í•œ ë¸íƒ€ê°’
dr = [-1, 1, 0, 0]
dc = [0, 0, -1, 1]

# 1. ë©ì–´ë¦¬ ì„¸ê¸° (ì´í•´í•˜ì‹  ë¡œì§ ê·¸ëŒ€ë¡œ!)
def count_chunks(current_ice):
    visited = [[False] * M for _ in range(N)] # ë§¤ë…„ ë©ì–´ë¦¬ë¥¼ ìƒˆë¡œ ì…€ ë•Œë§ˆë‹¤ ë°©ë¬¸ ê¸°ë¡ ì´ˆê¸°í™”
    chunks = 0
    for r, c in current_ice: # 9ë§Œ ì¹¸ ì „ìˆ˜ ì¡°ì‚¬ ëŒ€ì‹ , ì£¼ë¨¸ë‹ˆ(ëª…ë‹¨)ì— ë“  ë¹™ì‚° ì¢Œí‘œë§Œ í™•ì¸! (ì´ˆëŒ€ë°• ìµœì í™”)
        if ice[r][c] > 0 and not visited[r][c]:
            # ì•„ì§ ë°©ë¬¸í•˜ì§€ ì•Šì€ ë¹™ì‚°ì„ ë°œê²¬í•˜ë©´ ìƒˆë¡œìš´ ë©ì–´ë¦¬ BFS ì‹œì‘
            q = deque([(r, c)])
            visited[r][c] = True
            while q:
                curr_r, curr_c = q.popleft()
                for i in range(4):
                    nr, nc = curr_r + dr[i], curr_c + dc[i]
                    # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šê³ (ì´ë¯¸ ë°”ê¹¥ì€ 0ì´ë¼ ìƒê´€ì—†ìŒ), ë¹™ì‚°ì´ê³ , ë°©ë¬¸ ì•ˆ í–ˆë‹¤ë©´ ì—°ê²°ëœ ê²ƒ!
                    if ice[nr][nc] > 0 and not visited[nr][nc]:
                        visited[nr][nc] = True
                        q.append((nr, nc))
            chunks += 1 # í•œ ë²ˆì˜ BFS(í•œ ë©ì–´ë¦¬ íƒìƒ‰)ê°€ ëë‚˜ë©´ ì¹´ìš´íŠ¸ ì¦ê°€
    return chunks

year = 0
while ice_list: # ë¹™ì‚° ëª…ë‹¨(ice_list)ì´ ë¹„ì–´ìˆì§€ ì•Šì€ ë™ì•ˆ (ì¦‰, ë¹™ì‚°ì´ ë‹¤ ë…¹ì„ ë•Œê¹Œì§€)
    # 1. ë©ì–´ë¦¬ ê°œìˆ˜ í™•ì¸
    num = count_chunks(ice_list) 
    
    # ë©ì–´ë¦¬ê°€ 2ê°œ ì´ìƒì´ ë˜ëŠ” ìˆœê°„ì˜ 'ë…„ë„'ê°€ ì •ë‹µ!
    if num >= 2:
        print(year)
        break
    
    # 2. ë¹™ì‚° ë…¹ì´ê¸° (ì˜ˆì•½ ì‹œìŠ¤í…œ - ìŠ¤ëƒ…ìƒ· ê¸°ë²•)
    melt_list = [] # (í–‰, ì—´, ë…¹ì„ ì–‘)ì„ ì €ì¥í•  ì„ì‹œ ë°”êµ¬ë‹ˆ
    for r, c in ice_list:
        sea = 0
        for i in range(4):
            nr, nc = r + dr[i], c + dc[i]
            if ice[nr][nc] == 0:
                sea += 1 # ì£¼ë³€ ë°”ë‹¤(0)ì˜ ê°œìˆ˜ë§Œí¼ ë‚˜ì¤‘ì— í•´ë‹¹ë˜ëŠ” ê°’ ì°¨ê°
        if sea > 0: 
            melt_list.append((r, c, sea)) # ì§€ê¸ˆ ì¦‰ì‹œ ê¹ì§€ ì•Šê³ , 'ëˆ„ê°€ ì–¼ë§ˆë‚˜ ë…¹ì„ì§€' ì ì–´ë§Œ ë‘  (ë™ì‹œì„± ë³´ì¥)
    
    # 3. ì‹¤ì œë¡œ ë…¹ì´ê³ , ë‚´ë…„ì— ì‚´ì•„ë‚¨ì„ ë¹™ì‚°ë§Œ ìª½ì§€ ê°±ì‹  (Batch Update)
    for r, c, amount in melt_list:
        # max(0, ...)ë¥¼ ì¨ì„œ 0ë¯¸ë§Œìœ¼ë¡œ ë–¨ì–´ì§€ì§€ ì•Šê²Œ ë°©ì–´ (ì‚¼ì„± Aí˜• ë‹¨ê³¨ ìµœì í™” ê¸°ë²•)
        ice[r][c] = max(0, ice[r][c] - amount) 
    
    # 4. ë‹¤ì´ì–´íŠ¸ ê¸°ë²•: ë‚´ë…„ì—ë„ ì‚´ì•„ìˆì„ ë¹™ì‚°ë§Œ ì¶”ë ¤ì„œ ìƒˆë¡œìš´ ëª…ë‹¨ ì‘ì„±
    next_ice_list = []
    for r, c in ice_list:
        if ice[r][c] > 0:
            next_ice_list.append((r, c)) # ì•„ì§ ì•ˆ ë…¹ì€ ì• ë“¤ë§Œ ë‹¤ìŒ í•´ ìª½ì§€ë¡œ ì˜®ê²¨ë‹´ìŒ!
            
    ice_list = next_ice_list # ëª…ë‹¨ êµì²´ (ì—°ì‚° ëŒ€ìƒì´ ê°ˆìˆ˜ë¡ ì¤„ì–´ë“¦)
    year += 1
else:
    # ë£¨í”„ê°€ ëë‚  ë•Œê¹Œì§€ 2ë©ì–´ë¦¬ê°€ ì•ˆ ë˜ë©´ (ì¦‰, í•œ ë²ˆì— ë‹¤ ë…¹ì•„ë²„ë¦¬ê±°ë‚˜ ëê¹Œì§€ 1ë©ì–´ë¦¬ë©´) 0 ì¶œë ¥
    print(0)


'''
[ì‚¼ì„± Aí˜• í•©ê²©ì„ ìœ„í•œ 3ë‹¨ê³„ ì „ëµ í•µì‹¬ ìš”ì•½]

1ë‹¨ê³„: "ë²”ì¸ì€ ì´ ì•ˆì— ìˆì–´!" (ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ í™œìš©)
- 9ë§Œ ì¹¸(300x300)ì„ ë§¤ë²ˆ ëŒì§€ ë§ˆì„¸ìš”. 
- ë¹™ì‚°ì˜ ìœ„ì¹˜ë§Œ ë‹´ì€ ice_listë¥¼ ê´€ë¦¬í•˜ë©´ ì—°ì‚°ëŸ‰ì´ 1/100ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.

2ë‹¨ê³„: "ìŠ¤ëƒ…ìƒ· ì°ê¸°" (ì˜ˆì•½ ì‹œìŠ¤í…œ)
- ë¹™ì‚°ì´ ë…¹ëŠ” ê³¼ì •ì€ 'ë™ì‹œ'ì…ë‹ˆë‹¤. 
- í•œ ì¹¸ì´ 0ì´ ë˜ëŠ” ìˆœê°„ ì˜† ì¹¸ ì—°ì‚°ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡, melt_listì— ì ì–´ë‘” ë’¤ í•œ ë²ˆì— ë°˜ì˜(Batch Update)í•˜ì„¸ìš”.

3ë‹¨ê³„: "ë‹¤ì´ì–´íŠ¸ ì‹œí‚¤ê¸°" (ë¦¬ìŠ¤íŠ¸ ê°±ì‹ )
- ë…¹ì•„ì„œ ì‚¬ë¼ì§„ ë¹™ì‚°ì€ ì¦‰ì‹œ ëª…ë‹¨ì—ì„œ ì œì™¸í•˜ì„¸ìš”. 
- ë…„ë„ê°€ ì§€ë‚ ìˆ˜ë¡ ì½”ë“œëŠ” ì ì  ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤.
'''
"""

blocks = [
    {'type': 'divider', 'divider': {}},
    {'type': 'heading_1', 'heading_1': {'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ“ [Samsung A] ë¹™ì‚° - BFS ê¸°ë°˜ ë™ì‹œ ì‹œë®¬ë ˆì´ì…˜ (ì´ˆê³ ë†ë„ ìƒì„¸ ì£¼ì„)'}}]}},
    {'type': 'quote', 'quote': {'rich_text': [{'type': 'text', 'text': {'content': 'ì‚¬ìš©ìë‹˜ì˜ ì›ë³¸ ì½”ë“œ ì£¼ì„ì„ í•œ ê¸€ìë„ ë¹ ì§ì—†ì´ ë³´ì¡´í•˜ê³ , ë¼ì¸ë³„ ìƒì„¸ í•´ì„¤ì„ ì¶”ê°€í•˜ì—¬ "ê³µë¶€í•˜ëŠ” í•™ìƒ ì‹œì "ì—ì„œ ì™„ë²½íˆ ì´í•´ë˜ë„ë¡ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.'}}]}},
    {'type': 'heading_2', 'heading_2': {'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ’» Python ì „ì²´ ì •ë‹µ ì½”ë“œ (ë¼ì¸ë³„ ë°€ì°© í•´ì„¤)'}}]}},
    {'type': 'code', 'code': {'language': 'python', 'rich_text': [{'type': 'text', 'text': {'content': super_detailed_code}}]}},
    {'type': 'callout', 'callout': {'icon': {'type': 'emoji', 'emoji': 'ğŸ—ï¸'}, 'rich_text': [{'type': 'text', 'text': {'content': 'í•µì‹¬ êµ¬í˜„ í¬ì¸íŠ¸: ice_list(ëª…ë‹¨) -> melt_list(ì˜ˆì•½) -> next_ice_list(ê°±ì‹ )ë¡œ ì´ì–´ì§€ëŠ” 3ë‹¨ê³„ ë£¨í”„ê°€ ì´ ë¬¸ì œì˜ ì •ì„ì…ë‹ˆë‹¤. BFS ë©ì–´ë¦¬ ì¹´ìš´íŒ…ì€ ì´ ëª…ë‹¨ì´ ë°”ë€” ë•Œë§ˆë‹¤ ìˆ˜í–‰í•˜ì—¬ ì •í™•í•œ ìƒíƒœë¥¼ ì²´í¬í•˜ì„¸ìš”.'}}]}}
]

def update_notion():
    url = f'https://api.notion.com/v1/blocks/{PAGE_ID}/children'
    res = requests.get(url, headers=HEADERS)
    all_blocks = res.json().get('results', [])
    
    # ë°©ê¸ˆ ì „ ì‘ì—…ì—ì„œ ì¶”ê°€ëœ ğŸ“ [Samsung A] ë¹™ì‚° í—¤ë”ë¥¼ ì°¾ì•„ì„œ ê·¸ ì´í›„ë¥¼ ì‚­ì œ
    target_start_index = -1
    for i, b in enumerate(all_blocks):
        if b['type'] == 'heading_1' and 'ë¹™ì‚°' in b['heading_1']['rich_text'][0]['plain_text']:
            target_start_index = i
            break
            
    if target_start_index != -1:
        print(f"Deleting blocks from index {target_start_index} to clean up...")
        for b in all_blocks[target_start_index:]:
            requests.delete(f'https://api.notion.com/v1/blocks/{b["id"]}', headers=HEADERS)
            time.sleep(0.1)

    # ìƒˆë¡œìš´ ê³ ë†ë„ ë¸”ë¡ ì¶”ê°€
    for i in range(0, len(blocks), 5):
        chunk = blocks[i:i+5]
        requests.patch(url, headers=HEADERS, json={'children': chunk})
        time.sleep(1)
    print("Success: Super detailed content updated with line-by-line comments.")

if __name__ == '__main__':
    update_notion()
