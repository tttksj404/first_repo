import requests
import json


import os

def _get_notion_token():
    # Try multiple paths to find notion_key.txt
    current_dir = os.path.dirname(os.path.abspath(__file__))
    paths = [
        os.path.join(current_dir, 'notion_key.txt'),
        os.path.join(current_dir, '..', 'core', 'notion_key.txt'),
        os.path.join(current_dir, 'core', 'notion_key.txt'),
        os.path.join(os.getcwd(), 'notion_automation', 'core', 'notion_key.txt')
    ]
    for p in paths:
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                if token: return token
    return os.getenv("NOTION_TOKEN", "YOUR_NOTION_TOKEN_HERE")

NOTION_TOKEN = _get_notion_token()
HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}
PARENT_PAGE_ID = "2e7eacc8-175a-8035-8d30-ca6bf5e1c524"

def get_children(block_id):
    url = f"https://api.notion.com/v1/blocks/{block_id}/children"
    res = requests.get(url, headers=HEADERS)
    return res.json().get("results", [])

def append_checklist(page_id, title, items, mistakes):
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    blocks = [
        {"object": "block", "type": "divider", "divider": {}},
        {"object": "block", "type": "heading_2", "heading_2": {"rich_text": [{"type": "text", "text": {"content": f"âš ï¸ [ì‹¤ìˆ˜ ë°©ì§€] {title} ì˜¤ë‹µ ë…¸íŠ¸ & ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸"}}]}},
        {"object": "block", "type": "callout", "callout": {
            "icon": {"type": "emoji", "emoji": "ğŸš«"},
            "color": "red_background",
            "rich_text": [{"type": "text", "text": {"content": f"ê³¼ê±°ì˜ ì‹¤ìˆ˜ í¬ì¸íŠ¸: {mistakes}"}}]
        }}
    ]
    for item in items:
        blocks.append({
            "object": "block", 
            "type": "bulleted_list_item", 
            "bulleted_list_item": {"rich_text": [{"type": "text", "text": {"content": item}}]}
        })
    blocks.append({"object": "block", "type": "divider", "divider": {}})
    
    res = requests.patch(url, headers=HEADERS, json={"children": blocks})
    return res.status_code

# 1. Get all subpages
subpages = [b for b in get_children(PARENT_PAGE_ID) if b["type"] == "child_page"]

# 2. Define templates for each category (based on common patterns in the study)
checklists = {
    "í•´ì‹œ": {
        "mistakes": "Key ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ëˆ„ë½, ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ ë¯¸í¡.",
        "items": ["dict.get(key, default)ë¥¼ í™œìš©í•´ KeyErrorë¥¼ ë°©ì§€í–ˆëŠ”ê°€?", "Value ì—…ë°ì´íŠ¸ ì‹œ ê¸°ì¡´ ê°’ì„ ê³ ë ¤í–ˆëŠ”ê°€?"]
    },
    "ë°°ì—´ & ë¬¸ìì—´": {
        "mistakes": "ì¸ë±ìŠ¤ ë²”ìœ„(N-1) ì°©ê°, ìŠ¬ë¼ì´ì‹± ì‹œ ëì  ë¯¸í¬í•¨ ì‹¤ìˆ˜.",
        "items": ["range(start, end)ì—ì„œ endëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒì„ ì¸ì§€í–ˆëŠ”ê°€?", "ë¹ˆ ë¬¸ìì—´ì´ë‚˜ 1ê°œì§œë¦¬ ë°°ì—´ ë“± ê·¹ë‹¨ì  ì¼€ì´ìŠ¤ë¥¼ í™•ì¸í–ˆëŠ”ê°€?"]
    },
    "íˆ¬í¬ì¸í„°,ê·¸ë¦¬ë””": {
        "mistakes": "ê·¸ë¦¬ë”” ì •ë‹¹ì„± ì¦ëª… ë¶€ì¡±, í¬ì¸í„° ì´ë™ ì¡°ê±´(while) ì‹¤ìˆ˜.",
        "items": ["í˜„ì¬ì˜ ì„ íƒì´ í•­ìƒ ìµœì„ ì„ì„ ì¦ëª…í–ˆëŠ”ê°€?(ê·¸ë¦¬ë””)", "Left/Right í¬ì¸í„°ê°€ ì—­ì „ë˜ëŠ” ì¡°ê±´ì„ ëª…í™•íˆ ì„¤ì •í–ˆëŠ”ê°€?"]
    },
    "ì´ì§„ íƒìƒ‰": {
        "mistakes": "ë¬´í•œ ë£¨í”„(mid ê³„ì‚° ë°©ì‹), ì •ë ¬ë˜ì§€ ì•Šì€ ë°°ì—´ì—ì„œ íƒìƒ‰ ì‹œë„.",
        "items": ["ë°°ì—´ì´ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆëŠ”ê°€?", "low = mid + 1, high = mid - 1 ì²˜ë¦¬ë¥¼ ì •í™•íˆ í–ˆëŠ”ê°€?"]
    },
    "ì‹œë®¬ë ˆì´ì…˜": {
        "mistakes": "ì¡°ê±´ ëˆ„ë½, 2ì°¨ì› ë°°ì—´ ë³µì‚¬ ì‹œ ê¹Šì€ ë³µì‚¬(deepcopy) ë¯¸ì‚¬ìš©.",
        "items": ["ë¬¸ì œì˜ ëª¨ë“  ì œì•½ ì¡°ê±´ì„ ë¦¬ìŠ¤íŠ¸ì—…í•˜ê³  í•˜ë‚˜ì”© ì§€ì›Œë‚˜ê°”ëŠ”ê°€?", "ì›ë³¸ ë°°ì—´ì„ ë³´ì¡´í•´ì•¼ í•  ë•Œ copy()ë¥¼ ì ì ˆíˆ ì‚¬ìš©í–ˆëŠ”ê°€?"]
    },
    "DP": {
        "mistakes": "ì í™”ì‹ ì˜¤ë¥˜, ì´ˆê¸°ê°’(Base Case) ì„¤ì • ë¯¸í¡.",
        "items": ["ê°€ì¥ ì‘ì€ ë¬¸ì œì˜ ë‹µ(dp[0], dp[1])ì„ ì§ì ‘ ì†ìœ¼ë¡œ ê³„ì‚°í•´ ë³´ì•˜ëŠ”ê°€?", "Memoizationì„ í†µí•´ ì¤‘ë³µ ê³„ì‚°ì„ ë§‰ì•˜ëŠ”ê°€?"]
    },
    "ë‹¤ìµìŠ¤íŠ¸ë¼": {
        "mistakes": "ìš°ì„ ìˆœìœ„ í(heapq)ì— (ê±°ë¦¬, ë…¸ë“œ) ìˆœì„œê°€ ì•„ë‹Œ ì˜ëª»ëœ ìˆœì„œ ì‚½ì….",
        "items": ["ë°©ë¬¸í•œ ë…¸ë“œë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•˜ì§€ ì•Šë„ë¡ ìµœë‹¨ ê±°ë¦¬ í…Œì´ë¸”ì„ í™•ì¸í–ˆëŠ”ê°€?", "ê°€ì¤‘ì¹˜ê°€ ìŒìˆ˜ì¸ ê°„ì„ ì´ ì—†ëŠ”ì§€ í™•ì¸í–ˆëŠ”ê°€?"]
    }
}

for sp in subpages:
    page_id = sp["id"]
    title = sp["child_page"]["title"]
    
    # Matching title to our templates
    matched = False
    for key in checklists:
        if key in title:
            append_checklist(page_id, title, checklists[key]["items"], checklists[key]["mistakes"])
            print(f"Updated checklist for: {title}")
            matched = True
            break
    if not matched:
        print(f"Skipping or need custom logic for: {title}")

print("All applicable algorithm pages have been updated with checklists.")
