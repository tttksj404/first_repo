import requests
import json
import time


import os

def _get_notion_token():
    # Try multiple paths to find notion_key.txt
    current_dir = os.path.dirname(os.path.abspath(__file__))
    paths = [
        os.path.join(current_dir, 'notion_key.txt'),
        os.path.join(current_dir, '..', 'core', 'notion_key.txt'),
        os.path.join(current_dir, 'core', 'notion_key.txt'),
        os.path.join(os.getcwd(), 'notion_automation', 'core', 'notion_key.txt')
    ]
    for p in paths:
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                if token: return token
    return os.getenv("NOTION_TOKEN", "YOUR_NOTION_TOKEN_HERE")

NOTION_TOKEN = _get_notion_token()
HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

def rebuild_one(pid, title, blocks):
    print(f"--- [DEEP REBUILD] {title} ---")
    res_get = requests.get(f"https://api.notion.com/v1/blocks/{pid}/children", headers=HEADERS)
    for b in res_get.json().get("results", []):
        requests.delete(f"https://api.notion.com/v1/blocks/{b['id']}", headers=HEADERS)
        time.sleep(0.05)
    for i in range(0, len(blocks), 3):
        chunk = blocks[i:i+3]
        requests.patch(f"https://api.notion.com/v1/blocks/{pid}/children", headers=HEADERS, json={"children": chunk})
        time.sleep(0.5)
    res_verify = requests.get(f"https://api.notion.com/v1/blocks/{pid}/children", headers=HEADERS)
    actual_count = len(res_verify.json().get("results", []))
    print(f"VERIFIED: {title} ({actual_count} blocks)")
    return actual_count

# [Problem 16] ì´ì°¨ì› ë°°ì—´ê³¼ ì—°ì‚° (Detailed)
array_blocks = [
    {"type": "heading_1", "heading_1": {"rich_text": [{"type": "text", "text": {"content": "ğŸ“ [Problem 16] ì´ì°¨ì› ë°°ì—´ê³¼ ì—°ì‚° - ë¹ˆë„ ì •ë ¬ ë° ì „ì¹˜ í–‰ë ¬ ì—°ì‚°"}}]}},
    {"type": "quote", "quote": {"rich_text": [{"type": "text", "text": {"content": "í–‰ ë˜ëŠ” ì—´ì˜ ê¸¸ì´ì— ë”°ë¼ ì—°ì‚° ë°©í–¥ì„ ë°”ê¾¸ë©° ì •ë ¬ì„ ìˆ˜í–‰í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ìˆ«ìì˜ ë“±ì¥ ë¹ˆë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í‚¤ë¥¼ ì„¤ê³„í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤."}}]}},
    {"type": "heading_2", "heading_2": {"rich_text": [{"type": "text", "text": {"content": "ğŸ” í•µì‹¬ êµ¬í˜„ ë¡œì§"}}]}},
    {"type": "bulleted_list_item", "bulleted_list_item": {"rich_text": [{"type": "text", "text": {"content": "ë¹ˆë„ìˆ˜ ì •ë ¬: Counter í˜¹ì€ ë”•ì…”ë„ˆë¦¬ë¡œ ê°œìˆ˜ë¥¼ ì„¸ê³  (ê°œìˆ˜, ìˆ«ìê°’) ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. 0ì€ ì œì™¸í•©ë‹ˆë‹¤."}}]}},
    {"type": "bulleted_list_item", "bulleted_list_item": {"rich_text": [{"type": "text", "text": {"content": "í–‰/ì—´ ë³€í™˜: í–‰ ì—°ì‚°(R)ì„ ê¸°ë³¸ìœ¼ë¡œ ì§œê³ , ì—´ ì—°ì‚°(C) ì‹œì—ëŠ” zip(*)ì„ ì´ìš©í•´ ì „ì¹˜ì‹œí‚¨ ë’¤ ë‹¤ì‹œ R ì—°ì‚°ì„ ì ìš©í•©ë‹ˆë‹¤."}}]}},
    {"type": "heading_2", "heading_2": {"rich_text": [{"type": "text", "text": {"content": "ğŸ’» Python ì „ì²´ ì •ë‹µ ì½”ë“œ ì¡°ê°"}}]}},
    {"type": "code", "code": {"language": "python", "rich_text": [{"type": "text", "text": {"content": '''def sort_row(row):
    counts = Counter(row)
    if 0 in counts: del counts[0]
    # 1.ë¹ˆë„ 2.ìˆ«ì ìˆœ ì •ë ¬
    sorted_res = sorted(counts.items(), key=lambda x: (x[1], x[0]))
    new_row = []
    for num, cnt in sorted_res:
        new_row.extend([num, cnt])
    return new_row[:100] # ìµœëŒ€ 100ì œí•œ'''}}]}},
    {"type": "callout", "callout": {
        "icon": {"type": "emoji", "emoji": "ğŸ’¡"},
        "rich_text": [{"type": "text", "text": {"content": "í•™ìƒ ê°€ì´ë“œ: ì—°ì‚° í›„ í–‰/ì—´ì˜ ê¸¸ì´ë¥¼ ê°€ì¥ ê¸´ ê²ƒì— ë§ì¶° 0ìœ¼ë¡œ ì±„ìš°ëŠ” Padding ê³¼ì •ì—ì„œ ì¸ë±ìŠ¤ ì‹¤ìˆ˜ë¥¼ ì£¼ì˜í•˜ì„¸ìš”."}}]
    }}
]

rebuild_one("313eacc8-175a-8172-a54f-fef8428fb6e4", "Array Operation", array_blocks)
print("Updated Problem 16.")
